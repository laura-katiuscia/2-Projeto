{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNBNzNvDTvA5B5HwKzXReMf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laura-katiuscia/2-Projeto/blob/master/Machine_Learning_com_Analise_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDzjN8EcGhDR"
      },
      "outputs": [],
      "source": [
        "#Entendo conceito de Pipeline com Python para Machine Learning (e um conceito que\n",
        "\n",
        "# pode ser usada nas ling. Java, Python etc..Ela come√ßa antes DATALAKE E DATAHOUSE).\n",
        "\n",
        "# üìå Pipeline simples (fun√ß√µes em sequ√™ncia)\n",
        "def limpar_dados(dados):\n",
        "    return [x for x in dados if x is not None]\n",
        "\n",
        "def normalizar(dados):\n",
        "    max_val = max(dados)\n",
        "    return [x / max_val for x in dados]\n",
        "\n",
        "def treinar_modelo(dados):\n",
        "    print(\"Treinando modelo com:\", dados)\n",
        "\n",
        "# Pipeline\n",
        "dados = [10, 20, None, 30]\n",
        "dados = limpar_dados(dados)\n",
        "dados = normalizar(dados)\n",
        "treinar_modelo(dados)\n",
        "\n",
        "#üìå Ideia-chave: sa√≠da de uma fun√ß√£o vira entrada da pr√≥xima.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar arquivo colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "OkJHQXr2VZFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# l√™ o arquivo j√° carregado ‚úîÔ∏è Muito usado quando voc√™ quer limitar leituras de arquivos grandes.\n",
        "from itertools import islice\n",
        "\n",
        "with open('producao_alimentos.csv', 'r') as f:\n",
        "    for linha in islice(f, 6):\n",
        "        print(linha, end='')\n",
        "\n"
      ],
      "metadata": {
        "id": "nyi3x-s2VZXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Essa parte toda mas segunda parte do c√≥digo serve para testar a conectividade\n",
        "import csv\n",
        "import sqlite3\n",
        "\n",
        "#Cria novo banco de dados\n",
        "conn = sqlite3.connect('dsadb.db')\n",
        "\n",
        "# Adiciona esta linha para dropar a tabela se ela j√° existir\n",
        "conn.execute('DROP TABLE IF EXISTS producao')\n",
        "\n",
        "#Cria tabela para armazenar dos dados do arquivo producao_alimentos.csv\n",
        "conn.execute('''CREATE TABLE producao (\n",
        "            produto TEXT,\n",
        "            quantidade INTEGER,\n",
        "            preco_media REAL,\n",
        "            receita_media REAL\n",
        ")''')\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "8__fkQZ7cgQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#abre o arquivo CSV com os dados de produ√ß√£o de alimentos\n",
        "with open('producao_alimentos.csv', 'r') as file:\n",
        "\n",
        "#Cria um leitor de CSV para ler o arquivo\n",
        "  reader = csv.reader(file)\n",
        "\n",
        "  # pula primeira linha que cont√©m os cabe√ßalhos das colunas\n",
        "  next (reader)\n",
        "\n",
        "  #Conecta ao banco de dados\n",
        "  conn = sqlite3.connect('dsadb.db')\n",
        "\n",
        "\n",
        "  for row in reader:\n",
        "\n",
        "      conn.execute('INSERT INTO producao (produto, quantidade, preco_media, receita_media) VALUES (?, ?, ?, ?)', row)\n",
        "\n",
        "\n",
        "  conn.commit()\n",
        "  conn.close()\n",
        "\n",
        "  print(\"Job Conclu√≠do com Sucesso!\")"
      ],
      "metadata": {
        "id": "hSOch0N4cguN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Esse c√≥digo foi feito para responder o que foi pedido carrega somente quantidade\n",
        "#prouzida maior que 10 da coluna quantidade_produzida_kls  OBS: Essa atividade\n",
        "#JOB_V3.PY QUE E TRANSFORMA√á√ÉO DOS DADOS.\n",
        "import csv\n",
        "import sqlite3\n",
        "\n",
        "# Fun√ß√£o para remover o ponto nos dados da √∫ltima coluna\n",
        "def remove_ponto(valor):\n",
        "    return int(valor.replace('.', '')) #Essa fun√ß√£o usa replace que indetifica\n",
        "    #ponto e substitui por virgula e no final converte para n√∫mero inteiro.\n",
        "\n",
        "# Abre o arquivo CSV com os dados da produ√ß√£o de alimentos\n",
        "with open('producao_alimentos.csv', 'r') as file:\n",
        "\n",
        "    # Cria um leitor de CSV para ler o arquivo\n",
        "    reader = csv.reader(file)\n",
        "\n",
        "    # Pula a primeira linha, que cont√©m os cabe√ßalhos das colunas\n",
        "    next(reader)\n",
        "\n",
        "    # Conecta ao banco de dados\n",
        "    conn = sqlite3.connect('dsadb.db')\n",
        "\n",
        "    # Deleta a tabela existente, se houver\n",
        "    conn.execute('DROP TABLE IF EXISTS producao')  #Aula Pr√°tica 04, TRANSFORMA√á√ÉO\n",
        "    # DE DADOS, tirou os pontos que n√£o aparecia a casa decimal dos zeros dos valores.\n",
        "\n",
        "    # Cria uma nova tabela para armazenar os dados de produ√ß√£o de alimentos\n",
        "    conn.execute('''CREATE TABLE producao (\n",
        "                    produto TEXT,\n",
        "                    quantidade INTEGER,\n",
        "                    preco_medio REAL,\n",
        "                    receita_total INTEGER,\n",
        "                    margem_lucro REAL\n",
        "                )''')\n",
        "\n",
        "    #AQUI NO EXECUTE E DIFEREN√áA DO EXERCICIO 03 PARA 04 ONDE S√ì ACRESCENTA coluna\n",
        "    # com nome margem_lucro com resultado das colunas existentes que fez calculo\n",
        "\n",
        "    # Insere cada linha do arquivo com quantidade maior que 10 na tabela do banco de dados\n",
        "    #Aqui mant√™n a regra de neg√≥cio\n",
        "    for row in reader:\n",
        "        if int(row[1]) > 10:\n",
        "\n",
        "            # Remove o ponto do valor da √∫ltima coluna e converte para inteiro\n",
        "            row[3] = remove_ponto(row[3]) #√πltima linha que e receita_total e\n",
        "            #chama fun√ß√£o criada com nome remove_ponto\n",
        "\n",
        "            margem_lucro = (row[3] / float(row[1])) - float (row[2]) # Calculo 1¬∫ subtrai linha 1 menos a linha 2\n",
        "            #row.append(margem_lucro)\n",
        "\n",
        "            # Insere o registro no banco de dados sendo que margem de lucro n√£o existe na origem isso deixa ele pronto pra uso\n",
        "            #coluna margem e pra colocar resultado das colunas j√° existentes\n",
        "            conn.execute('INSERT INTO producao (produto, quantidade, preco_medio, receita_total, margem_lucro) VALUES (?, ?, ?, ?, ?)', (row[0], row[1], row[2], row[3], margem_lucro))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "print(\"Job Conclu√≠do com Sucesso! Para v√™ o resultado abra no \")"
      ],
      "metadata": {
        "id": "V8MkXD2UTToc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Pipeline com Pandas (An√°lise de Dados), muito usado no pr√©-processamento de dados %%\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"idade\": [20, 25, None, 30],\n",
        "    \"salario\": [2000, None, 3000, 4000]\n",
        "})\n",
        "\n",
        "pipeline = (\n",
        "    df\n",
        "    .dropna()\n",
        "    .assign(\n",
        "        idade_norm=lambda x: x[\"idade\"] / x[\"idade\"].max(),\n",
        "        salario_norm=lambda x: x[\"salario\"] / x[\"salario\"].max()\n",
        "    )\n",
        ")\n",
        "\n",
        "print(pipeline)\n",
        "\n",
        "#üìå Ideal para ETL (Extract, Transform, Load).\n"
      ],
      "metadata": {
        "id": "4hLbgfaAqPMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ Pipeline profissional com scikit-learn (Machine Learning)\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Dados\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"modelo\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "# Treinar\n",
        "pipeline.fit(X_treino, y_treino)\n",
        "\n",
        "# Avaliar\n",
        "print(\"Acur√°cia:\", pipeline.score(X_teste, y_teste))\n",
        "\n",
        "#üî• O que acontece aqui? StandardScaler ‚Üí normaliza os dados, LogisticRegression ‚Üí treina o modelo, Tudo acontece automaticamente em ordem\n",
        "\n",
        "# üìå Evita erros, vazamento de dados e facilita deploy.\n"
      ],
      "metadata": {
        "id": "jogwJkKv31-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4Ô∏è‚É£ Pipeline com colunas diferentes (num√©ricas e categ√≥ricas), Muito comum em projetos reais.\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "preprocessador = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), [\"idade\", \"salario\"]),\n",
        "    (\"cat\", OneHotEncoder(), [\"sexo\"])\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"prep\", preprocessador),\n",
        "    (\"modelo\", RandomForestClassifier())\n",
        "])\n",
        "\n",
        "#Esse pipeline N√ÉO gera resposta sozinho. A resposta do modelo s√≥ aparece depois que voc√™ treina e faz uma predi√ß√£o.\n",
        "\n",
        "# üëâ A resposta final do pipeline ser√°: Uma classe prevista, por exemplo: 0 ‚Üí n√£o compra, 1 ‚Üí compra\n"
      ],
      "metadata": {
        "id": "2hge_wCF8Bss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Criando um dataset dummy para treino (com idade, salario, sexo e um target)\n",
        "# Isso √© necess√°rio porque o pipeline com ColumnTransformer espera dados com essas colunas para ser treinado\n",
        "data_treino = pd.DataFrame({\n",
        "    \"idade\": [25, 35, 45, 22, 38, 50],\n",
        "    \"salario\": [2500, 3500, 4500, 2200, 3800, 5000],\n",
        "    \"sexo\": [\"F\", \"M\", \"F\", \"M\", \"F\", \"M\"],\n",
        "    \"target\": [0, 1, 0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "# Separando features (X) e target (y) para o treino\n",
        "X_treino_dummy = data_treino[[\"idade\", \"salario\", \"sexo\"]]\n",
        "y_treino_dummy = data_treino[\"target\"]\n",
        "\n",
        "# Treinar o pipeline com os dados dummy\n",
        "pipeline.fit(X_treino_dummy, y_treino_dummy)\n",
        "\n",
        "novo_cliente = pd.DataFrame({\n",
        "    \"idade\": [30],\n",
        "    \"salario\": [4000],\n",
        "    \"sexo\": [\"F\"]\n",
        "})\n",
        "\n",
        "resposta = pipeline.predict(novo_cliente)\n",
        "probabilidade = pipeline.predict_proba(novo_cliente)\n",
        "\n",
        "print(\"Classe prevista:\", resposta)\n",
        "print(\"Probabilidade:\", probabilidade)\n",
        "\n",
        "#Resposta classe prevista 0 sig. que ele n√£o vai comprar"
      ],
      "metadata": {
        "id": "CJvjR7Bc8B9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}